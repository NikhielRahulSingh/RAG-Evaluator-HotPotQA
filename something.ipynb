{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>actual_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard</td>\n",
       "      <td>George Boscawen, 9th Viscount Falmouth is a fo...</td>\n",
       "      <td>the Guards Division, Foot Guards regiments</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard</td>\n",
       "      <td>When Vladimir Kashpur portrayed Baba Yaga she ...</td>\n",
       "      <td>trio of sisters</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which musician has a solo punk rock project: T...</td>\n",
       "      <td>Frank Anthony Iero, Jr.</td>\n",
       "      <td>[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>A Disney voice actor has won which Emmy award?</td>\n",
       "      <td>Outstanding Supporting Actor</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which north-western suburb of Adelaide lies wi...</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level                                           question  \\\n",
       "0  hard  George Boscawen, 9th Viscount Falmouth is a fo...   \n",
       "1  hard  When Vladimir Kashpur portrayed Baba Yaga she ...   \n",
       "2  hard  Which musician has a solo punk rock project: T...   \n",
       "3  hard     A Disney voice actor has won which Emmy award?   \n",
       "4  hard  Which north-western suburb of Adelaide lies wi...   \n",
       "\n",
       "                                       answer  \\\n",
       "0  the Guards Division, Foot Guards regiments   \n",
       "1                             trio of sisters   \n",
       "2                     Frank Anthony Iero, Jr.   \n",
       "3                Outstanding Supporting Actor   \n",
       "4                                  Birkenhead   \n",
       "\n",
       "                            actual_contexts  \n",
       "0            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  \n",
       "2  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]  \n",
       "3  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]  \n",
       "4  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = \"dunzhang/stella_en_400M_v5\"\n",
    "number = 5000\n",
    "with open(f'clustering/graph/connected_graph.pkl', 'rb') as file: connected_graph = pickle.load(file)\n",
    "with open(f'clustering/graph/cluster_graph.pkl', 'rb') as file: cluster_graph = pickle.load(file)\n",
    "with open(f'embeddings/{model}/hard/{number}/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "with open(f'embeddings/{model}/hard/{number}/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "\n",
    "hotpot_qa_df['actual_contexts'] = hotpot_qa_df['actual_contexts'].apply(lambda x: [int(i) for i in x])\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict,List\n",
    "import networkx\n",
    "import random\n",
    "\n",
    "cluster_node_embedding_sample:Dict[int,List[float]] = {}\n",
    "for cluster_id in cluster_graph.keys():\n",
    "    graph:networkx.Graph = cluster_graph[cluster_id]\n",
    "    node:int = list(graph.nodes)[0]#random.choice(list(graph.nodes)) # select a random node from the cluster\n",
    "    cluster_node_embedding_sample[cluster_id] = contexts[str(node)].embedding\n",
    "\n",
    "start_node = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A* Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cosine_similarity_gpu(list_A, list_B):\n",
    "    # Convert lists to tensors and move to GPU\n",
    "    A = torch.tensor(list_A, dtype=torch.float32).cuda()\n",
    "    B = torch.tensor(list_B, dtype=torch.float32).cuda()\n",
    "\n",
    "    # Compute cosine similarity on GPU\n",
    "    cos_sim = F.cosine_similarity(A.unsqueeze(0), B.unsqueeze(0))\n",
    "\n",
    "    return cos_sim.item()  # Convert tensor result to a Python float\n",
    "\n",
    "def get_nodes(question_embedding,clusters,contexts=contexts):\n",
    "    cosine_similarities = []\n",
    "    nodes = []\n",
    "    for cluster in clusters:\n",
    "        for node in list(cluster_graph[cluster].nodes):\n",
    "            nodes.append(node)\n",
    "\n",
    "    # Calculate cosine similarities and store them with node identifiers\n",
    "    for node in nodes:\n",
    "        node_embedding = contexts[str(node)].embedding\n",
    "        cosine_sim = cosine_similarity_gpu(question_embedding, node_embedding)\n",
    "        cosine_similarities.append((node, cosine_sim))  # Store as (node, similarity)\n",
    "\n",
    "    # Sort the nodes based on the highest similarity\n",
    "    sorted_nodes = sorted(cosine_similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract sorted node identifiers and their similarities\n",
    "    sorted_node_ids = [node for node, sim in sorted_nodes]\n",
    "    sorted_similarities = [sim for node, sim in sorted_nodes]\n",
    "\n",
    "    return sorted_node_ids[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.60\n",
    "\n",
    "retrieved_contexts = []\n",
    "for question in tqdm(hotpot_qa_df['question'], desc=\"Retrieving contexts\", unit=\"question\"):\n",
    "\n",
    "    question_embedding = question.embedding\n",
    "\n",
    "    max_cluster_similarities:List[int] = []\n",
    "    max_similarity:float = -float('inf')\n",
    "    max_similirity_node:int = None\n",
    "\n",
    "    for id,sample_embedding in zip(cluster_node_embedding_sample.keys(),cluster_node_embedding_sample.values()):\n",
    "        cosine_sim = cosine_similarity_gpu(question_embedding,sample_embedding)\n",
    "        if cosine_sim > max_similarity: \n",
    "            max_similarity = cosine_sim\n",
    "            max_similirity_node = id\n",
    "        if cosine_sim > THRESHOLD:max_cluster_similarities.append(id)\n",
    "\n",
    "    if len(max_cluster_similarities) == 0: \n",
    "        max_cluster_similarities.append(max_similirity_node)\n",
    "    \n",
    "    retrieved_contexts.append(get_nodes(question_embedding,max_cluster_similarities))\n",
    "\n",
    "hotpot_qa_df[\"Cluster_Retrieval\"] = retrieved_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_index(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "context_embeddings = []\n",
    "\n",
    "for text_node in contexts.values():\n",
    "    context_embeddings.append(text_node.embedding)\n",
    "    \n",
    "def lists_to_arrays(list_of_lists):\n",
    "    return np.array([np.array(lst) for lst in list_of_lists], dtype=object)\n",
    "\n",
    "query_embeddings = [query.embedding for query in hotpot_qa_df['question'].tolist()]\n",
    "\n",
    "def retrieve_contexts(index):\n",
    "    retrieved_results = [] \n",
    "    for query_embedding in tqdm(query_embeddings):\n",
    "        D, I = index.search(np.array(query_embedding).reshape(1, -1), 10)\n",
    "        results = I[0].tolist()\n",
    "        retrieved_results.append(results)\n",
    "    return retrieved_results\n",
    "\n",
    "actual_contexts = hotpot_qa_df['actual_contexts'].tolist()\n",
    "def evaluate_index(retrieved_contexts,actual_contexts=actual_contexts):\n",
    "    df = pd.DataFrame({\n",
    "                        'actual_contexts': actual_contexts,\n",
    "                        'retrieved_contexts': retrieved_contexts\n",
    "                    })\n",
    "    evaluator = RetrieverEvaluator(df,'retrieved_contexts')\n",
    "    order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "    order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "    print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "    print(f\"order aware metrics   : {order_aware_metrics}\")\n",
    "\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "def beir_evaluation(actual_contexts,results):\n",
    "    actual_contexts_dict = {\n",
    "        str(i): {str(doc_id): 1 for doc_id in context} for i, context in enumerate(actual_contexts)\n",
    "    }\n",
    "    results_dict = {\n",
    "        str(i): {str(doc_id): rank + 1 for rank, doc_id in enumerate(result)} for i, result in enumerate(results)\n",
    "    }\n",
    "\n",
    "    ndcg, map_score, recall, precision = EvaluateRetrieval.evaluate(\n",
    "        actual_contexts_dict, results_dict, k_values=[10]\n",
    "    )\n",
    "    print(\"ndcg:\", ndcg)\n",
    "    print(\"map:\", map_score)\n",
    "    print(\"mrr:\", EvaluateRetrieval.evaluate_custom(actual_contexts_dict, results_dict, [5,10], metric=\"mrr\"))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"recall:\", recall)\n",
    "    print(\"precision:\", precision)\n",
    "    print(\"acc:\", EvaluateRetrieval.evaluate_custom(actual_contexts_dict, results_dict, [5,10], metric=\"acc\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Methods : IP & L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Product (IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:45<00:00, 109.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: {'NDCG@10': 0.31884}\n",
      "map: {'MAP@10': 0.17334}\n",
      "mrr: {'MRR@5': 0.3094, 'MRR@10': 0.35986}\n",
      "\n",
      "recall: {'Recall@10': 0.3848}\n",
      "precision: {'P@10': 0.38146}\n",
      "acc: {'Accuracy@5': 0.6036, 'Accuracy@10': 0.9938}\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(len(query_embeddings[0]))\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "contexts = retrieve_contexts(index)\n",
    "beir_evaluation(actual_contexts,contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:46<00:00, 108.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: {'NDCG@10': 0.32358}\n",
      "map: {'MAP@10': 0.17793}\n",
      "mrr: {'MRR@5': 0.32001, 'MRR@10': 0.37008}\n",
      "\n",
      "recall: {'Recall@10': 0.38762}\n",
      "precision: {'P@10': 0.38436}\n",
      "acc: {'Accuracy@5': 0.6048, 'Accuracy@10': 0.9938}\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "index = faiss.IndexFlatL2(len(query_embeddings[0]))\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "retrieved_contexts = retrieve_contexts(index)\n",
    "beir_evaluation(actual_contexts,retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Navigable Small World "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 5116.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: {'NDCG@10': 0.30287}\n",
      "map: {'MAP@10': 0.16825}\n",
      "mrr: {'MRR@5': 0.30056, 'MRR@10': 0.34862}\n",
      "\n",
      "recall: {'Recall@10': 0.36139}\n",
      "precision: {'P@10': 0.3586}\n",
      "acc: {'Accuracy@5': 0.5656, 'Accuracy@10': 0.9434}\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "max_neighbours = 16\n",
    "ef_search = 10\n",
    "ef_construction = 256\n",
    "\n",
    "index = faiss.IndexHNSWFlat(len(query_embeddings[0]), max_neighbours)\n",
    "index.hnsw.efSearch = ef_search\n",
    "index.hnsw.efConstruction = ef_construction\n",
    "\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "contexts = retrieve_contexts(index)\n",
    "beir_evaluation(actual_contexts,contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 then IndexFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "class HybridSearch:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "        # BM25 initialization\n",
    "        tokenized_corpus = [text_node.text.split(\" \") for text_node in documents]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        self.document_embeddings = [text_node.embedding for text_node in documents]\n",
    "        \n",
    "        # FAISS initialization\n",
    "        self.index = faiss.IndexFlatIP(len(self.document_embeddings[0]))\n",
    "        self.index.add(lists_to_arrays(self.document_embeddings))\n",
    "\n",
    "    def search(self, query, top_n=10):\n",
    "        # BM25 search\n",
    "        bm25_scores = self.bm25.get_scores(query.query_str.split(\" \"))\n",
    "        top_docs_indices = np.argsort(bm25_scores)[-top_n*5:]\n",
    "        print(top_docs_indices)\n",
    "        print()\n",
    "        \n",
    "        # Get embeddings of top documents from BM25 search\n",
    "        top_docs_embeddings = [self.document_embeddings[i] for i in top_docs_indices]\n",
    "\n",
    "        query_embedding = np.array(query.embedding).reshape(1, -1)\n",
    "\n",
    "        # FAISS search on the top documents\n",
    "        sub_index = faiss.IndexFlatIP(len(self.document_embeddings[0]))\n",
    "        sub_index.add(np.array(top_docs_embeddings))\n",
    "        distances, sub_dense_ranked_indices = sub_index.search(np.array(query_embedding), top_n)\n",
    "\n",
    "        # Map FAISS results back to original document indices\n",
    "        final_ranked_indices = [top_docs_indices[i] for i in sub_dense_ranked_indices[0]]\n",
    "\n",
    "        # Retrieve the actual documents\n",
    "        ranked_docs = [int(self.documents[i].id_) for i in final_ranked_indices]\n",
    "        return ranked_docs\n",
    "\n",
    "def retrieve_contexts(hs):\n",
    "    retrieved_results = [] \n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "    for query in tqdm(questions[:2]):\n",
    "        retrieved_results.append(hs.search(query, top_n=10))\n",
    "    return retrieved_results\n",
    "\n",
    "hs = HybridSearch(list(contexts.values()))\n",
    "results = retrieve_contexts(hs)\n",
    "evaluate_index(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchResults(keys=[1, 3, 7, 9, 11095, 24286, 38539, 10, 29819, 2771], scores=array([0.00727236, 0.00646719, 0.00515218, 0.00448899, 0.00323097,\n",
       "       0.0031733 , 0.00315333, 0.00310439, 0.00306923, 0.00300407],\n",
       "      dtype=float32), normalized=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from baguetter.indices import FaissDenseIndex,BMXSparseIndex,MultiIndex\n",
    "import pickle\n",
    "\n",
    "def load_data(model_name):\n",
    "    with open(f'embeddings/{model_name}/hard/5000/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "    with open(f'embeddings/{model_name}/hard/5000/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "\n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "\n",
    "\n",
    "    return [q.embedding for q in questions],contexts\n",
    "\n",
    "dense_model = \"dunzhang/stella_en_400M_v5\"\n",
    "dense_questions,dense_contexts = load_data(dense_model)\n",
    "result = {i: i + 1 for i in range(len(context_embeddings))}\n",
    "# Create an index\n",
    "dense_index = FaissDenseIndex(index,\"dense_index\",len(query_embeddings[0]),result)\n",
    "\n",
    "_ = dense_index.search(np.array(dense_questions[0]),top_k=10)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 49776/49776 [00:12<00:00, 4094.39it/s]\n",
      "Building doc-term matrix: 100%|██████████| 49776/49776 [00:01<00:00, 48878.58it/s]\n",
      "Building inverted index: 100%|██████████| 116039/116039 [00:18<00:00, 6383.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchResults(keys=[6, 0, 2, 8, 7, 4, 1, 3, 9, 32657], scores=array([44.847828, 42.857597, 40.865738, 39.84939 , 28.379486, 26.272427,\n",
      "       26.180256, 24.131647, 23.960619, 19.673334], dtype=float32), normalized=False)\n"
     ]
    }
   ],
   "source": [
    "from baguetter.indices import *\n",
    "\n",
    "\n",
    "context_str = [x.text for x in list(dense_contexts.values())]\n",
    "sparse_index = BMXSparseIndex(index_name=\"BMX_Test\")\n",
    "sparse_index.add_many(keys=result,values=context_str,show_progress=True)\n",
    "\n",
    "questions = hotpot_qa_df[\"question\"].tolist()\n",
    "question_str = [q.query_str for q in questions]\n",
    "x = sparse_index.search(question_str[0],top_k=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: {'NDCG@10': 0.51022}\n",
      "map: {'MAP@10': 0.34057}\n",
      "mrr: {'MRR@5': 0.57872, 'MRR@10': 0.58973}\n",
      "\n",
      "recall: {'Recall@10': 0.56587}\n",
      "precision: {'P@10': 0.56196}\n",
      "acc: {'Accuracy@5': 0.9198, 'Accuracy@10': 0.9984}\n"
     ]
    }
   ],
   "source": [
    "multi_index = MultiIndex()\n",
    "\n",
    "idx = multi_index.add_index(sparse_index)\n",
    "idx = multi_index.add_index(dense_index)\n",
    "\n",
    "embeddings = [q.embedding for q in hotpot_qa_df[\"question\"].tolist()]\n",
    "question_strs = [q.query_str for q in hotpot_qa_df[\"question\"].tolist()]\n",
    "\n",
    "results = []\n",
    "for question,embedding in zip(question_strs,embeddings):\n",
    "    embedding_np = np.array(embedding)\n",
    "    query = {\n",
    "             \"BMX_Test\":question,\"dense_index\":embedding_np\n",
    "             }\n",
    "    x = idx.search(query=query,\n",
    "                top_k=10)\n",
    "    res = x.keys[:10]\n",
    "    results.append(res)\n",
    "\n",
    "beir_evaluation(actual_contexts,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg: {'NDCG@10': 0.58479}\n",
    "map: {'MAP@10': 0.43666}\n",
    "mrr: {'MRR@5': 0.59957, 'MRR@10': 0.61119}\n",
    "\n",
    "recall: {'Recall@10': 0.64619}\n",
    "precision: {'P@10': 0.64222}\n",
    "acc: {'Accuracy@5': 0.9164, 'Accuracy@10': 0.9984}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
