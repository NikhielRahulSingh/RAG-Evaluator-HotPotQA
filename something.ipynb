{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>actual_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard</td>\n",
       "      <td>George Boscawen, 9th Viscount Falmouth is a fo...</td>\n",
       "      <td>the Guards Division, Foot Guards regiments</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard</td>\n",
       "      <td>When Vladimir Kashpur portrayed Baba Yaga she ...</td>\n",
       "      <td>trio of sisters</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which musician has a solo punk rock project: T...</td>\n",
       "      <td>Frank Anthony Iero, Jr.</td>\n",
       "      <td>[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>A Disney voice actor has won which Emmy award?</td>\n",
       "      <td>Outstanding Supporting Actor</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which north-western suburb of Adelaide lies wi...</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level                                           question  \\\n",
       "0  hard  George Boscawen, 9th Viscount Falmouth is a fo...   \n",
       "1  hard  When Vladimir Kashpur portrayed Baba Yaga she ...   \n",
       "2  hard  Which musician has a solo punk rock project: T...   \n",
       "3  hard     A Disney voice actor has won which Emmy award?   \n",
       "4  hard  Which north-western suburb of Adelaide lies wi...   \n",
       "\n",
       "                                       answer  \\\n",
       "0  the Guards Division, Foot Guards regiments   \n",
       "1                             trio of sisters   \n",
       "2                     Frank Anthony Iero, Jr.   \n",
       "3                Outstanding Supporting Actor   \n",
       "4                                  Birkenhead   \n",
       "\n",
       "                            actual_contexts  \n",
       "0            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  \n",
       "2  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]  \n",
       "3  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]  \n",
       "4  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = \"dunzhang/stella_en_400M_v5\"\n",
    "\n",
    "with open(f'clustering/graph/connected_graph.pkl', 'rb') as file: connected_graph = pickle.load(file)\n",
    "with open(f'clustering/graph/cluster_graph.pkl', 'rb') as file: cluster_graph = pickle.load(file)\n",
    "with open(f'embeddings/{model}/hard/3000/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "with open(f'embeddings/{model}/hard/3000/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "\n",
    "hotpot_qa_df['actual_contexts'] = hotpot_qa_df['actual_contexts'].apply(lambda x: [int(i) for i in x])\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict,List\n",
    "import networkx\n",
    "import random\n",
    "\n",
    "cluster_node_embedding_sample:Dict[int,List[float]] = {}\n",
    "for cluster_id in cluster_graph.keys():\n",
    "    graph:networkx.Graph = cluster_graph[cluster_id]\n",
    "    node:int = list(graph.nodes)[0]#random.choice(list(graph.nodes)) # select a random node from the cluster\n",
    "    cluster_node_embedding_sample[cluster_id] = contexts[str(node)].embedding\n",
    "\n",
    "start_node = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A* Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cosine_similarity_gpu(list_A, list_B):\n",
    "    # Convert lists to tensors and move to GPU\n",
    "    A = torch.tensor(list_A, dtype=torch.float32).cuda()\n",
    "    B = torch.tensor(list_B, dtype=torch.float32).cuda()\n",
    "\n",
    "    # Compute cosine similarity on GPU\n",
    "    cos_sim = F.cosine_similarity(A.unsqueeze(0), B.unsqueeze(0))\n",
    "\n",
    "    return cos_sim.item()  # Convert tensor result to a Python float\n",
    "\n",
    "def get_nodes(question_embedding,clusters,contexts=contexts):\n",
    "    cosine_similarities = []\n",
    "    nodes = []\n",
    "    for cluster in clusters:\n",
    "        for node in list(cluster_graph[cluster].nodes):\n",
    "            nodes.append(node)\n",
    "\n",
    "    # Calculate cosine similarities and store them with node identifiers\n",
    "    for node in nodes:\n",
    "        node_embedding = contexts[str(node)].embedding\n",
    "        cosine_sim = cosine_similarity_gpu(question_embedding, node_embedding)\n",
    "        cosine_similarities.append((node, cosine_sim))  # Store as (node, similarity)\n",
    "\n",
    "    # Sort the nodes based on the highest similarity\n",
    "    sorted_nodes = sorted(cosine_similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract sorted node identifiers and their similarities\n",
    "    sorted_node_ids = [node for node, sim in sorted_nodes]\n",
    "    sorted_similarities = [sim for node, sim in sorted_nodes]\n",
    "\n",
    "    return sorted_node_ids[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.60\n",
    "\n",
    "retrieved_contexts = []\n",
    "for question in tqdm(hotpot_qa_df['question'], desc=\"Retrieving contexts\", unit=\"question\"):\n",
    "\n",
    "    question_embedding = question.embedding\n",
    "\n",
    "    max_cluster_similarities:List[int] = []\n",
    "    max_similarity:float = -float('inf')\n",
    "    max_similirity_node:int = None\n",
    "\n",
    "    for id,sample_embedding in zip(cluster_node_embedding_sample.keys(),cluster_node_embedding_sample.values()):\n",
    "        cosine_sim = cosine_similarity_gpu(question_embedding,sample_embedding)\n",
    "        if cosine_sim > max_similarity: \n",
    "            max_similarity = cosine_sim\n",
    "            max_similirity_node = id\n",
    "        if cosine_sim > THRESHOLD:max_cluster_similarities.append(id)\n",
    "\n",
    "    if len(max_cluster_similarities) == 0: \n",
    "        max_cluster_similarities.append(max_similirity_node)\n",
    "    \n",
    "    retrieved_contexts.append(get_nodes(question_embedding,max_cluster_similarities))\n",
    "\n",
    "hotpot_qa_df[\"Cluster_Retrieval\"] = retrieved_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_index(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving contexts: 100%|██████████| 3000/3000 [00:05<00:00, 583.86question/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster_Retrieval:\n",
      "order unaware metrics : {'avg precision@10': 0.41919999999999996, 'avg recall@10': 0.42191333333333336, 'avg F1@10': 0.4198677938994976}\n",
      "order aware metrics   : {'avg mrr': 0.47018115866717053, 'avg ndcg': 0.5143042362129897, 'mean avg precision': 0.3659910714285714}\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "\n",
    "documents = []\n",
    "ids = []\n",
    "embeddings = []\n",
    "metadatas = []\n",
    "\n",
    "for context in contexts.values():\n",
    "    documents.append(context.text)\n",
    "    ids.append(context.id_)\n",
    "    embeddings.append(context.embedding)\n",
    "    metadatas.append({'caption': context.metadata['caption']})\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"my_collection\",metadata={\"hnsw:space\": \"cosine\"})\n",
    "collection.add(documents=documents,\n",
    "               ids=ids,\n",
    "               embeddings=embeddings,\n",
    "               metadatas=metadatas)\n",
    "\n",
    "retrieved_contexts = []\n",
    "for question in tqdm(hotpot_qa_df['question'], desc=\"Retrieving contexts\", unit=\"question\"):\n",
    "\n",
    "    question_embedding = question.embedding\n",
    "    result = collection.query(\n",
    "                                query_embeddings=[question_embedding], # Chroma will embed this for you\n",
    "                                n_results=10 # how many results to return\n",
    "                              )\n",
    "    retrieved_contexts.append([int(node) for node in result[\"ids\"][0]] )\n",
    "\n",
    "hotpot_qa_df[\"Vector_Similarity_Retrieval\"] = retrieved_contexts\n",
    "\n",
    "\n",
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'Vector_Similarity_Retrieval')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "print(f\"Cluster_Retrieval:\")\n",
    "print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "print(f\"order aware metrics   : {order_aware_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "context_embeddings = []\n",
    "\n",
    "for text_node in contexts.values():\n",
    "    context_embeddings.append(text_node.embedding)\n",
    "    \n",
    "def lists_to_arrays(list_of_lists):\n",
    "    return np.array([np.array(lst) for lst in list_of_lists], dtype=object)\n",
    "\n",
    "query_embeddings = [query.embedding for query in hotpot_qa_df['question'].tolist()]\n",
    "\n",
    "def retrieve_contexts(index):\n",
    "    retrieved_results = [] \n",
    "    for query_embedding in tqdm(query_embeddings):\n",
    "        D, I = index.search(np.array(query_embedding).reshape(1, -1), 10)\n",
    "        results = I[0].tolist()\n",
    "        retrieved_results.append(results)\n",
    "    return retrieved_results\n",
    "\n",
    "actual_contexts = hotpot_qa_df['actual_contexts'].tolist()\n",
    "def evaluate_index(retrieved_contexts,actual_contexts=actual_contexts):\n",
    "    df = pd.DataFrame({\n",
    "                        'actual_contexts': actual_contexts,\n",
    "                        'retrieved_contexts': retrieved_contexts\n",
    "                    })\n",
    "    evaluator = RetrieverEvaluator(df,'retrieved_contexts')\n",
    "    order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "    order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "    print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "    print(f\"order aware metrics   : {order_aware_metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Methods : IP & L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Product (IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:17<00:00, 175.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order unaware metrics : {'avg precision@10': 0.4238, 'avg recall@10': 0.42674666666666666, 'avg F1@10': 0.4245090175062565}\n",
      "order aware metrics   : {'avg mrr': 0.4852274370643319, 'avg ndcg': 0.525069685827108, 'mean avg precision': 0.3673632671957672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatIP(len(query_embeddings[0]))\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "contexts = retrieve_contexts(index)\n",
    "evaluate_index(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:19<00:00, 156.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order unaware metrics : {'avg precision@10': 0.4288, 'avg recall@10': 0.4316933333333333, 'avg F1@10': 0.42950981507991104}\n",
      "order aware metrics   : {'avg mrr': 0.4875897411711598, 'avg ndcg': 0.5294633020383592, 'mean avg precision': 0.37254224867724867}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "index = faiss.IndexFlatL2(len(query_embeddings[0]))\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "retrieved_contexts = retrieve_contexts(index)\n",
    "evaluate_index(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Navigable Small World "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 6971.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order unaware metrics : {'avg precision@10': 0.40723333333333334, 'avg recall@10': 0.40941666666666665, 'avg F1@10': 0.4077799617129026}\n",
      "order aware metrics   : {'avg mrr': 0.472127469345763, 'avg ndcg': 0.5019419625831757, 'mean avg precision': 0.3533193896447468}\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "max_neighbours = 16\n",
    "ef_search = 10\n",
    "ef_construction = 256\n",
    "\n",
    "index = faiss.IndexHNSWFlat(len(query_embeddings[0]), max_neighbours)\n",
    "index.hnsw.efSearch = ef_search\n",
    "index.hnsw.efConstruction = ef_construction\n",
    "\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "contexts = retrieve_contexts(index)\n",
    "evaluate_index(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 then IndexFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "class HybridSearch:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "\n",
    "        # BM25 initialization\n",
    "        tokenized_corpus = [text_node.text.split(\" \") for text_node in documents]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        self.document_embeddings = [text_node.embedding for text_node in documents]\n",
    "        \n",
    "        # FAISS initialization\n",
    "        self.index = faiss.IndexFlatIP(len(self.document_embeddings[0]))\n",
    "        self.index.add(lists_to_arrays(self.document_embeddings))\n",
    "\n",
    "    def search(self, query, top_n=10):\n",
    "        # BM25 search\n",
    "        bm25_scores = self.bm25.get_scores(query.query_str.split(\" \"))\n",
    "        top_docs_indices = np.argsort(bm25_scores)[-top_n*5:]\n",
    "        print(top_docs_indices)\n",
    "        print()\n",
    "        \n",
    "        # Get embeddings of top documents from BM25 search\n",
    "        top_docs_embeddings = [self.document_embeddings[i] for i in top_docs_indices]\n",
    "\n",
    "        query_embedding = np.array(query.embedding).reshape(1, -1)\n",
    "\n",
    "        # FAISS search on the top documents\n",
    "        sub_index = faiss.IndexFlatIP(len(self.document_embeddings[0]))\n",
    "        sub_index.add(np.array(top_docs_embeddings))\n",
    "        distances, sub_dense_ranked_indices = sub_index.search(np.array(query_embedding), top_n)\n",
    "\n",
    "        # Map FAISS results back to original document indices\n",
    "        final_ranked_indices = [top_docs_indices[i] for i in sub_dense_ranked_indices[0]]\n",
    "\n",
    "        # Retrieve the actual documents\n",
    "        ranked_docs = [int(self.documents[i].id_) for i in final_ranked_indices]\n",
    "        print(ranked_docs)\n",
    "        print()\n",
    "        print()\n",
    "        return ranked_docs\n",
    "\n",
    "def retrieve_contexts(hs):\n",
    "    retrieved_results = [] \n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "    for query in tqdm(questions[:2]):\n",
    "        retrieved_results.append(hs.search(query, top_n=10))\n",
    "    return retrieved_results\n",
    "\n",
    "hs = HybridSearch(list(contexts.values()))\n",
    "results = retrieve_contexts(hs)\n",
    "evaluate_index(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchResults(keys=[1, 3, 7, 9, 11095, 24286, 10, 29819, 2771, 4689], scores=array([0.00727236, 0.00646719, 0.00515218, 0.00448899, 0.00323097,\n",
       "       0.0031733 , 0.00310439, 0.00306923, 0.00300407, 0.00300362],\n",
       "      dtype=float32), normalized=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from baguetter.indices import FaissDenseIndex,BMXSparseIndex,MultiIndex\n",
    "import pickle\n",
    "\n",
    "def load_data(model_name):\n",
    "    with open(f'embeddings/{model_name}/hard/3000/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "    with open(f'embeddings/{model_name}/hard/3000/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "\n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "\n",
    "\n",
    "    return [q.embedding for q in questions],contexts\n",
    "\n",
    "dense_model = \"dunzhang/stella_en_400M_v5\"\n",
    "dense_questions,dense_contexts = load_data(dense_model)\n",
    "result = {i: i + 1 for i in range(len(context_embeddings))}\n",
    "# Create an index\n",
    "dense_index = FaissDenseIndex(index,\"dense_index\",len(query_embeddings[0]),result)\n",
    "\n",
    "_ = dense_index.search(np.array(dense_questions[0]),top_k=10)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/29874 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 29874/29874 [00:10<00:00, 2985.82it/s]\n",
      "Calculating Unique Tokens: 100%|██████████| 29874/29874 [00:00<00:00, 170039.58it/s]\n",
      "Converting tokens to token IDs: 100%|██████████| 29874/29874 [00:01<00:00, 20010.72it/s]\n",
      "Counting Tokens: 100%|██████████| 29874/29874 [00:00<00:00, 88972.03it/s]\n",
      "Computing IDF: 100%|██████████| 85399/85399 [00:00<00:00, 1745102.98it/s]\n",
      "Computing BM25 Scores: 100%|██████████| 29874/29874 [00:00<00:00, 38807.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchResults(keys=[6, 0, 2, 8, 7, 4, 1, 3, 9, 5483], scores=array([23.43219 , 21.867594, 20.710741, 20.615828, 14.102193, 13.447546,\n",
      "       13.258555, 11.743535, 11.357604,  9.480198], dtype=float32), normalized=False)\n"
     ]
    }
   ],
   "source": [
    "from baguetter.indices import *\n",
    "\n",
    "\n",
    "context_str = [x.text for x in list(dense_contexts.values())]\n",
    "sparse_index = BM25SparseIndex(index_name=\"BMX_Test\")\n",
    "sparse_index.add_many(keys=result,values=context_str,show_progress=True)\n",
    "\n",
    "questions = hotpot_qa_df[\"question\"].tolist()\n",
    "question_str = [q.query_str for q in questions]\n",
    "x = sparse_index.search(question_str[0],top_k=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index = MultiIndex()\n",
    "\n",
    "idx = multi_index.add_index(sparse_index)\n",
    "#idx = multi_index.add_index(dense_index)\n",
    "\n",
    "embeddings = [q.embedding for q in hotpot_qa_df[\"question\"].tolist()]\n",
    "question_strs = [q.query_str for q in hotpot_qa_df[\"question\"].tolist()]\n",
    "\n",
    "results = []\n",
    "for question,embedding in zip(question_strs,embeddings):\n",
    "    embedding_np = np.array(embedding)\n",
    "    query = {\n",
    "             \"BMX_Test\":question#,\"dense_index\":embedding_np\n",
    "             }\n",
    "    x = idx.search(query=query,\n",
    "                top_k=10)\n",
    "    res = x.keys[:10]\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 0, 2, 8, 7, 4, 1, 3, 9, 5483]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>actual_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard</td>\n",
       "      <td>George Boscawen, 9th Viscount Falmouth is a fo...</td>\n",
       "      <td>the Guards Division, Foot Guards regiments</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard</td>\n",
       "      <td>When Vladimir Kashpur portrayed Baba Yaga she ...</td>\n",
       "      <td>trio of sisters</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which musician has a solo punk rock project: T...</td>\n",
       "      <td>Frank Anthony Iero, Jr.</td>\n",
       "      <td>[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>A Disney voice actor has won which Emmy award?</td>\n",
       "      <td>Outstanding Supporting Actor</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which north-western suburb of Adelaide lies wi...</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level                                           question  \\\n",
       "0  hard  George Boscawen, 9th Viscount Falmouth is a fo...   \n",
       "1  hard  When Vladimir Kashpur portrayed Baba Yaga she ...   \n",
       "2  hard  Which musician has a solo punk rock project: T...   \n",
       "3  hard     A Disney voice actor has won which Emmy award?   \n",
       "4  hard  Which north-western suburb of Adelaide lies wi...   \n",
       "\n",
       "                                       answer  \\\n",
       "0  the Guards Division, Foot Guards regiments   \n",
       "1                             trio of sisters   \n",
       "2                     Frank Anthony Iero, Jr.   \n",
       "3                Outstanding Supporting Actor   \n",
       "4                                  Birkenhead   \n",
       "\n",
       "                            actual_contexts  \n",
       "0            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  \n",
       "2  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]  \n",
       "3  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]  \n",
       "4  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg: {'NDCG@10': 0.64287}\n",
      "map: {'MAP@10': 0.5064}\n",
      "mrr: {'MRR@5': 0.64042, 'MRR@10': 0.64858}\n",
      "\n",
      "recall: {'Recall@10': 0.70542}\n",
      "precision: {'P@10': 0.7017}\n",
      "acc: {'Accuracy@5': 0.94233, 'Accuracy@10': 0.99967}\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "actual_contexts_dict = {\n",
    "    str(i): {str(doc_id): 1 for doc_id in context} for i, context in enumerate(actual_contexts)\n",
    "}\n",
    "results_dict = {\n",
    "    str(i): {str(doc_id): rank + 1 for rank, doc_id in enumerate(result)} for i, result in enumerate(results)\n",
    "}\n",
    "\n",
    "ndcg, map_score, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    actual_contexts_dict, results_dict, k_values=[10]\n",
    ")\n",
    "print(\"ndcg:\", ndcg)\n",
    "print(\"map:\", map_score)\n",
    "print(\"mrr:\", EvaluateRetrieval.evaluate_custom(actual_contexts_dict, results_dict, [5,10], metric=\"mrr\"))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"recall:\", recall)\n",
    "print(\"precision:\", precision)\n",
    "print(\"acc:\", EvaluateRetrieval.evaluate_custom(actual_contexts_dict, results_dict, [5,10], metric=\"acc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order unaware metrics : {'avg precision@10': 0.7017333333333333, 'avg recall@10': 0.70545, 'avg F1@10': 0.7027293429726666}\n",
      "order aware metrics   : {'avg mrr': 0.3558409853972453, 'avg ndcg': 0.7594046268482914, 'mean avg precision': 0.6463913189720333}\n"
     ]
    }
   ],
   "source": [
    "evaluate_index(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMX Alone\n",
    "order unaware metrics : {'avg precision@10': 0.6945666666666666, 'avg recall@10': 0.6983166666666666, 'avg F1@10': 0.6955756880019065}\n",
    "order aware metrics   : {'avg mrr': 0.35843464600655073, 'avg ndcg': 0.7521629937272413, 'mean avg precision': 0.6377886370937264}\n",
    "\n",
    "BM25 Alone  \n",
    "order unaware metrics : {'avg precision@10': 0.7017666666666668, 'avg recall@10': 0.7054833333333332, 'avg F1@10': 0.7027626763060001}\n",
    "order aware metrics   : {'avg mrr': 0.35583251795162507, 'avg ndcg': 0.7594267115894429, 'mean avg precision': 0.6464246523053666}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLADE then IndexFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_data(model_name):\n",
    "    with open(f'embeddings/{model_name}/hard/500/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "    with open(f'embeddings/{model_name}/hard/500/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "\n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "\n",
    "\n",
    "    return [q.embedding for q in questions],contexts\n",
    "\n",
    "dense_model = \"dunzhang/stella_en_400M_v5\"\n",
    "dense_questions,dense_contexts = load_data(dense_model)\n",
    "\n",
    "sparse_model = \"naver/splade-v3\"\n",
    "sparse_questions,sparse_contexts = load_data(sparse_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
