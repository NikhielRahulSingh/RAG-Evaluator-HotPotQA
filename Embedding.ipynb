{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HotPotQA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>actual_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard</td>\n",
       "      <td>George Boscawen, 9th Viscount Falmouth is a fo...</td>\n",
       "      <td>the Guards Division, Foot Guards regiments</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard</td>\n",
       "      <td>When Vladimir Kashpur portrayed Baba Yaga she ...</td>\n",
       "      <td>trio of sisters</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which musician has a solo punk rock project: T...</td>\n",
       "      <td>Frank Anthony Iero, Jr.</td>\n",
       "      <td>[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>A Disney voice actor has won which Emmy award?</td>\n",
       "      <td>Outstanding Supporting Actor</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which north-western suburb of Adelaide lies wi...</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level                                           question  \\\n",
       "0  hard  George Boscawen, 9th Viscount Falmouth is a fo...   \n",
       "1  hard  When Vladimir Kashpur portrayed Baba Yaga she ...   \n",
       "2  hard  Which musician has a solo punk rock project: T...   \n",
       "3  hard     A Disney voice actor has won which Emmy award?   \n",
       "4  hard  Which north-western suburb of Adelaide lies wi...   \n",
       "\n",
       "                                       answer  \\\n",
       "0  the Guards Division, Foot Guards regiments   \n",
       "1                             trio of sisters   \n",
       "2                     Frank Anthony Iero, Jr.   \n",
       "3                Outstanding Supporting Actor   \n",
       "4                                  Birkenhead   \n",
       "\n",
       "                            actual_contexts  \n",
       "0            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  \n",
       "2  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]  \n",
       "3  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]  \n",
       "4  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.hotpot_data_loader import HotPotQA\n",
    "\n",
    "SEED = 42\n",
    "SAMPLE = 5000\n",
    "DIFFICULTY = \"hard\"\n",
    "\n",
    "contexts, hotpot_qa_df = HotPotQA(SAMPLE=SAMPLE, DIFFICULTY=DIFFICULTY, SEED=SEED).get_data()\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check machine configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n",
      "CUDA Version:  12.4\n",
      "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "FlashAttention available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Version: \", torch.version.cuda)\n",
    "print(\"Device name:\", torch.cuda.get_device_properties(\"cuda\").name)\n",
    "print(\"FlashAttention available:\", torch.backends.cuda.flash_sdp_enabled())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Embeddding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\nikhi\\anaconda3\\envs\\masters\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\nikhi\\anaconda3\\envs\\masters\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\nikhi\\anaconda3\\envs\\masters\\Lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "    ^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from utils.embedders.sentence_transformer_embedder import SentenceTransformerEmbedder\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.schema import QueryBundle\n",
    "\n",
    "embedder = SentenceTransformerEmbedder(huggingface_token = \"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\",\n",
    "                                       cache_loc         = \"D:/Users/nikhi/.cache/huggingface/hub/\",\n",
    "                                       model_save_loc    = \"D:/Users/nikhi/hugging_face_embedding_models\")\n",
    "\n",
    "model_name=\"dunzhang/stella_en_1.5B_v5\" #dunzhang/stella_en_1.5B_v5\n",
    "#embedder.download_embedding_model(model_name=model_name)\n",
    "\n",
    "model = SentenceTransformer(model_name_or_path = f\"D:/Users/nikhi/hugging_face_embedding_models/{model_name}\", \n",
    "                            trust_remote_code=True,\n",
    "                            device=\"cuda\",\n",
    "                            model_kwargs={\"attn_implementation\": \"eager\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665113de496740499e3e791b6b10ea06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_prompt_name = \"s2p_query\"\n",
    "queries = [(doc.text if isinstance(doc, TextNode) else doc.query_str) for doc in hotpot_qa_df['question']]\n",
    "query_embeddings = model.encode(queries,show_progress_bar=True,prompt_name=query_prompt_name)\n",
    "for embedding,query in zip(query_embeddings,hotpot_qa_df['question']):\n",
    "    query.embedding = embedding.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Actual Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dd9996e8fc4d11ad5abeb45ab2f188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = [(doc.text if isinstance(doc, TextNode) else doc.query_str) for doc in contexts.values()]\n",
    "doc_embeddings = model.encode(docs,show_progress_bar=True)\n",
    "for embedding,document in zip(doc_embeddings,contexts.values()):document.embedding = embedding.tolist()\n",
    "context_similarities = model.similarity(doc_embeddings,doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded chunks saved to : embeddings/dunzhang/stella_en_400M_v5/hard/5000 as contexts.pkl\n",
      "df saved to : embeddings/dunzhang/stella_en_400M_v5/hard/5000 as embedded_queries.pkl\n",
      "similarity matrix saved to : embeddings/dunzhang/stella_en_400M_v5/hard/5000 as similarity_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "save_dir = f\"embeddings/{model_name}/{DIFFICULTY}/{SAMPLE}\"\n",
    "\n",
    "embedder.save_embeddings(contexts=contexts,\n",
    "                         df=hotpot_qa_df,\n",
    "                         df_name = f'df',\n",
    "                         similarity_matrix=context_similarities,\n",
    "                         save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model_name=\"dunzhang/stella_en_400M_v5\" #dunzhang/stella_en_1.5B_v5\n",
    "SAMPLE = 500\n",
    "DIFFICULTY = \"500\"\n",
    "save_dir = f\"embeddings/{model_name}/{DIFFICULTY}/{SAMPLE}\"\n",
    "with open(f'embeddings/dunzhang/stella_en_400M_v5/hard/500/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "with open(f'embeddings/dunzhang/stella_en_400M_v5/hard/500/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "with open(f'embeddings/dunzhang/stella_en_400M_v5/hard/500/similarity_matrix.pkl', 'rb') as f:context_similarities = pickle.load(f)\n",
    "\n",
    "hotpot_qa_df['actual_contexts'] = hotpot_qa_df['actual_contexts'].apply(lambda x: [int(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from utils.embedding_stores.graph import graph_db\n",
    "\n",
    "from typing import List\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.schema import QueryBundle\n",
    "\n",
    "def create_retriever(chunk_nodes,k):\n",
    "\n",
    "\n",
    "    bm25_retriever = BM25Retriever.from_defaults(nodes=chunk_nodes, similarity_top_k=k)\n",
    "\n",
    "    print(f\"BM-25 Retriever created\")\n",
    "    return bm25_retriever    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_retrievers import bm25\n",
    "from utils.embedding_retrievers.graph import a_star,bfs\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "def retrieve_chunks_bm25(db,query_bundles:QueryBundle):\n",
    "    \n",
    "    chunks = bm25.perform_retrieval(query_bundles,db)\n",
    "    \n",
    "    with open('.tmp/benchmarks.pkl', 'rb') as f: \n",
    "        benchmarks_dict = pickle.load(f)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        ids = [int(t_node.node.id_) for t_node in chunk]\n",
    "        benchmarks_dict[\"retrieved_contexts\"].append(ids)\n",
    "\n",
    "    df_benchmark = pd.DataFrame(benchmarks_dict)\n",
    "    return df_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_retrievers.vector import vec_similarity\n",
    "from utils.embedding_stores.vector import vec_db\n",
    "\n",
    "V = vec_db.create_or_load_vector_db(db_name=f\"chromadb2\",\n",
    "                                        save_loc=\"chromadb\",\n",
    "                                        docs=contexts)\n",
    "\n",
    "hotpot_qa_df['vec_retrieved'] = vec_similarity.perform_retrieval(hotpot_qa_df,V)\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_stores.graph import graph_db\n",
    "from utils.embedding_retrievers.graph import a_star\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "G = graph_db.create_graph(contexts_list,context_similarities,THRESHOLD,save_dir+f\"/graph_store/{THRESHOLD}\",True)\n",
    "G = graph_db.load_graph(save_dir+f\"/graph_store/{THRESHOLD}\")\n",
    "nodes_with_score = a_star.perform_retrieval(hotpot_qa_df,G,THRESHOLD)\n",
    "node_ids = [[str(node.id_) for node in node_with_score[:10]] for node_with_score in nodes_with_score]\n",
    "hotpot_qa_df['a_star_retrieved'] = node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'a_star_retrieved')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "print(f\"\\nA star:\")\n",
    "print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "print(f\"order aware metrics   : {order_aware_metrics}\")\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'vec_retrieved')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "order_aware_metrics = evaluator.get_order_aware_metrics()\n",
    "\n",
    "print(f\"\\nVec sim:\")\n",
    "print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "print(f\"order aware metrics   : {order_aware_metrics}\")\n",
    "hotpot_qa_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms\n",
    "\n",
    "x = algorithms.surprise_communities\n",
    "def make_communities(alg,G):    \n",
    "    print(f\"creating community\")\n",
    "    community = eval(f\"algorithms.{alg}(G)\")\n",
    "    print(f\"community created\")\n",
    "    analyze_clusters(community)\n",
    "    show_community_member_counts(community)\n",
    "\n",
    "    return community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "def get_embeddings_from_community(contexts,community):\n",
    "    embeddings = []\n",
    "    for node in community:\n",
    "        text_node = contexts[str(node)]\n",
    "        embeddings.append(text_node.embedding)\n",
    "    embeddings_tensor = torch.tensor(embeddings).to('cuda')\n",
    "    \n",
    "    return embeddings_tensor\n",
    "\n",
    "def get_similarity_matrix(tensors):\n",
    "    similarity_matrix = util.cos_sim(tensors, tensors)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "def create_community_graph(community,similarity_matrix):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(community)\n",
    "\n",
    "    for i in range(len(community)):\n",
    "        for j in range(i+1, len(community)):\n",
    "            similarity = similarity_matrix[i][j]\n",
    "    \n",
    "            G.add_edge(community[i], community[j], weight=similarity.item())\n",
    "    return G\n",
    "\n",
    "# embeddings = get_embeddings_from_community(contexts=contexts,community=clusters[0])\n",
    "# embeddings_tensor = torch.tensor(embeddings).to('cuda')\n",
    "# sim_mat = get_similarity_matrix(embeddings_tensor)\n",
    "# comm_graph  = create_community_graph(clusters[0],sim_mat)\n",
    "# graph_db.visualize_graph(comm_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_comm = make_communities('louvain',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leiden Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_comm = make_communities('leiden',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_comm = make_communities('surprise_communities',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walktrap Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walktrap_comm = make_communities('walktrap',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_communities(community)\n",
    "draw_graph(G, pos, community.communities)\n",
    "analyze_clusters(community)\n",
    "louvain_cluster_counts = get_community_member_counts(community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'a_star_retrieved')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=1) \n",
    "#order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "print(order_unaware_metrics)\n",
    "#print(order_aware_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25 = create_retriever(embedded_chunks,10)\n",
    "df_results_bm25 = retrieve_chunks_bm25(BM25,embedded_queries)\n",
    "evaluate_results(df_results_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "#G = graph_db.create_graph(embedded_chunks,chunk_similarities,THRESHOLD,save_dir)\n",
    "df_results = retrieve_chunk_graph(db=G,\n",
    "                                  traversal_method='a star',\n",
    "                                  threshold=THRESHOLD,\n",
    "                                  query_bundles=embedded_queries)\n",
    "evaluate_results(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
