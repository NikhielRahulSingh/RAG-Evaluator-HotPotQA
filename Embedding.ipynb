{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HotPotQA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf9ba1554299025d62a2db</td>\n",
       "      <td>What position on the Billboard Top 100 did Ali...</td>\n",
       "      <td>[[The Other Side of Love, [\"The Other Side of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a7befac5542996dd594b857</td>\n",
       "      <td>What year did the British politician born in 1...</td>\n",
       "      <td>[[Philip Cowley, [Philip Cowley is a British p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ab80e565542991d32223821</td>\n",
       "      <td>Which franchise was founded in 1978, Chuck E. ...</td>\n",
       "      <td>[[The Rock-afire Explosion, [The Rock-a-fire E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ae09e595542993d6555ebc0</td>\n",
       "      <td>Roden Cutler House is owned by an electricity ...</td>\n",
       "      <td>[[Askin–Cutler ministry (1965–68), [The Askin–...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ae6094555429929b0807a96</td>\n",
       "      <td>What year was the inspiration for the 2009 dra...</td>\n",
       "      <td>[[Mick Fanning, [Michael Eugene \"Mick\" Fanning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5adf9ba1554299025d62a2db   \n",
       "1  5a7befac5542996dd594b857   \n",
       "2  5ab80e565542991d32223821   \n",
       "3  5ae09e595542993d6555ebc0   \n",
       "4  5ae6094555429929b0807a96   \n",
       "\n",
       "                                            question  \\\n",
       "0  What position on the Billboard Top 100 did Ali...   \n",
       "1  What year did the British politician born in 1...   \n",
       "2  Which franchise was founded in 1978, Chuck E. ...   \n",
       "3  Roden Cutler House is owned by an electricity ...   \n",
       "4  What year was the inspiration for the 2009 dra...   \n",
       "\n",
       "                                             context  \n",
       "0  [[The Other Side of Love, [\"The Other Side of ...  \n",
       "1  [[Philip Cowley, [Philip Cowley is a British p...  \n",
       "2  [[The Rock-afire Explosion, [The Rock-a-fire E...  \n",
       "3  [[Askin–Cutler ministry (1965–68), [The Askin–...  \n",
       "4  [[Mick Fanning, [Michael Eugene \"Mick\" Fanning...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"data/hotpot_test_fullwiki_v1.json\")#data\\hotpot_test_fullwiki_v1.json\n",
    "questions = df[\"question\"].tolist()\n",
    "contexts = df[\"context\"].tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "context_docs:List[Document] = []\n",
    "benchmarks:List[List[int]] = []\n",
    "context_id:int = 0\n",
    "\n",
    "for context in contexts:\n",
    "    benchmark_context_ids:List[int] = []\n",
    "\n",
    "    for title_and_sentences in context:\n",
    "        title = title_and_sentences[0]\n",
    "        benchmark_context_ids.append(context_id)\n",
    "\n",
    "        sentences = \" \".join(title_and_sentences[1])\n",
    "        sentence = ' '.join(sentences.split())\n",
    "\n",
    "        document:Document = Document(page_content=sentence,metadata={\"ID\":context_id,\"Title\":title})\n",
    "        context_docs.append(document)\n",
    "\n",
    "        context_id += 1\n",
    "\n",
    "    benchmarks.append(benchmark_context_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check machine configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n",
      "CUDA Version:  12.4\n",
      "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "FlashAttention available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Version: \", torch.version.cuda)\n",
    "print(\"Device name:\", torch.cuda.get_device_properties(\"cuda\").name)\n",
    "print(\"FlashAttention available:\", torch.backends.cuda.flash_sdp_enabled())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Embeddding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\nikhi\\anaconda3\\envs\\masters\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Users\\nikhi\\anaconda3\\envs\\masters\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from utils.embedders.sentence_transformer_embedder import SentenceTransformerEmbedder\n",
    "\n",
    "embedder = SentenceTransformerEmbedder(huggingface_token = \"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\",\n",
    "                                       cache_loc         = \"D:/Users/nikhi/.cache/huggingface/hub/\",\n",
    "                                       model_save_loc    = \"D:/Users/nikhi/hugging_face_embedding_models\")\n",
    "\n",
    "model_name=\"mixedbread-ai/mxbai-embed-large-v1\" #dunzhang/stella_en_400M_v5\n",
    "#embedder.download_embedding_model(model_name=model_name)\n",
    "\n",
    "model = SentenceTransformer(model_name_or_path = f\"D:/Users/nikhi/hugging_face_embedding_models/{model_name}\", \n",
    "                            trust_remote_code=True,\n",
    "                            device=\"cuda\",\n",
    "                            model_kwargs={\"attn_implementation\": \"eager\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac3cf2223cd466b90d44be19c80e040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_embeddings = model.encode(questions,prompt_name=\"query\",show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed Actual Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77451dfc4c334609af03f70d1d21fd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = [f\"Title: {doc.metadata[\"Title\"]}\\nExtract: {doc.page_content}\" for doc in context_docs]\n",
    "doc_embeddings = model.encode(docs,show_progress_bar=True)\n",
    "context_similarities = model.similarity(doc_embeddings,doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "save_dir = f\"{f\"test/{model_name}/\"}\"\n",
    "if not os.path.exists(save_dir):os.makedirs(save_dir)\n",
    "\n",
    "#np.save(f\"{save_dir}/context_embeddings.npy\",doc_embeddings)\n",
    "np.save(f\"{save_dir}/query_embeddings.npy\",query_embeddings)\n",
    "#np.save(f\"{save_dir}/context_similarities.npy\",context_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "model_name=\"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "\n",
    "query_embeddings = numpy.load(f\"test/{model_name}/query_embeddings.npy\")\n",
    "context_embeddings = numpy.load(f\"test/{model_name}/context_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from utils.embedding_stores.graph import graph_db\n",
    "\n",
    "from typing import List\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.schema import QueryBundle\n",
    "\n",
    "def create_retriever(chunk_nodes,k):\n",
    "\n",
    "\n",
    "    bm25_retriever = BM25Retriever.from_defaults(nodes=chunk_nodes, similarity_top_k=k)\n",
    "\n",
    "    print(f\"BM-25 Retriever created\")\n",
    "    return bm25_retriever    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_retrievers import bm25\n",
    "from utils.embedding_retrievers.graph import a_star,bfs\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "def retrieve_chunks_bm25(db,query_bundles:QueryBundle):\n",
    "    \n",
    "    chunks = bm25.perform_retrieval(query_bundles,db)\n",
    "    \n",
    "    with open('.tmp/benchmarks.pkl', 'rb') as f: \n",
    "        benchmarks_dict = pickle.load(f)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        ids = [int(t_node.node.id_) for t_node in chunk]\n",
    "        benchmarks_dict[\"retrieved_contexts\"].append(ids)\n",
    "\n",
    "    df_benchmark = pd.DataFrame(benchmarks_dict)\n",
    "    return df_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_retrievers.vector import vec_similarity\n",
    "from utils.embedding_stores.vector import vec_db\n",
    "\n",
    "V = vec_db.create_or_load_vector_db(db_name=f\"chromadb2\",\n",
    "                                        save_loc=\"chromadb\",\n",
    "                                        docs=contexts)\n",
    "\n",
    "hotpot_qa_df['vec_retrieved'] = vec_similarity.perform_retrieval(hotpot_qa_df,V)\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embedding_stores.graph import graph_db\n",
    "from utils.embedding_retrievers.graph import a_star\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "G = graph_db.create_graph(contexts_list,context_similarities,THRESHOLD,save_dir+f\"/graph_store/{THRESHOLD}\",True)\n",
    "G = graph_db.load_graph(save_dir+f\"/graph_store/{THRESHOLD}\")\n",
    "nodes_with_score = a_star.perform_retrieval(hotpot_qa_df,G,THRESHOLD)\n",
    "node_ids = [[str(node.id_) for node in node_with_score[:10]] for node_with_score in nodes_with_score]\n",
    "hotpot_qa_df['a_star_retrieved'] = node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'a_star_retrieved')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "print(f\"\\nA star:\")\n",
    "print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "print(f\"order aware metrics   : {order_aware_metrics}\")\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'vec_retrieved')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=10) \n",
    "order_aware_metrics = evaluator.get_order_aware_metrics()\n",
    "\n",
    "print(f\"\\nVec sim:\")\n",
    "print(f\"order unaware metrics : {order_unaware_metrics}\")\n",
    "print(f\"order aware metrics   : {order_aware_metrics}\")\n",
    "hotpot_qa_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms\n",
    "\n",
    "x = algorithms.surprise_communities\n",
    "def make_communities(alg,G):    \n",
    "    print(f\"creating community\")\n",
    "    community = eval(f\"algorithms.{alg}(G)\")\n",
    "    print(f\"community created\")\n",
    "    analyze_clusters(community)\n",
    "    show_community_member_counts(community)\n",
    "\n",
    "    return community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "def get_embeddings_from_community(contexts,community):\n",
    "    embeddings = []\n",
    "    for node in community:\n",
    "        text_node = contexts[str(node)]\n",
    "        embeddings.append(text_node.embedding)\n",
    "    embeddings_tensor = torch.tensor(embeddings).to('cuda')\n",
    "    \n",
    "    return embeddings_tensor\n",
    "\n",
    "def get_similarity_matrix(tensors):\n",
    "    similarity_matrix = util.cos_sim(tensors, tensors)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "def create_community_graph(community,similarity_matrix):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(community)\n",
    "\n",
    "    for i in range(len(community)):\n",
    "        for j in range(i+1, len(community)):\n",
    "            similarity = similarity_matrix[i][j]\n",
    "    \n",
    "            G.add_edge(community[i], community[j], weight=similarity.item())\n",
    "    return G\n",
    "\n",
    "# embeddings = get_embeddings_from_community(contexts=contexts,community=clusters[0])\n",
    "# embeddings_tensor = torch.tensor(embeddings).to('cuda')\n",
    "# sim_mat = get_similarity_matrix(embeddings_tensor)\n",
    "# comm_graph  = create_community_graph(clusters[0],sim_mat)\n",
    "# graph_db.visualize_graph(comm_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_comm = make_communities('louvain',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leiden Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_comm = make_communities('leiden',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_comm = make_communities('surprise_communities',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walktrap Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walktrap_comm = make_communities('walktrap',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_communities(community)\n",
    "draw_graph(G, pos, community.communities)\n",
    "analyze_clusters(community)\n",
    "louvain_cluster_counts = get_community_member_counts(community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation_metrics.retriever import RetrieverEvaluator\n",
    "\n",
    "evaluator = RetrieverEvaluator(hotpot_qa_df,'a_star_retrieved')\n",
    "\n",
    "order_unaware_metrics = evaluator.get_order_unaware_metrics(k=1) \n",
    "#order_aware_metrics = evaluator.get_order_aware_metrics() \n",
    "\n",
    "print(order_unaware_metrics)\n",
    "#print(order_aware_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25 = create_retriever(embedded_chunks,10)\n",
    "df_results_bm25 = retrieve_chunks_bm25(BM25,embedded_queries)\n",
    "evaluate_results(df_results_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "#G = graph_db.create_graph(embedded_chunks,chunk_similarities,THRESHOLD,save_dir)\n",
    "df_results = retrieve_chunk_graph(db=G,\n",
    "                                  traversal_method='a star',\n",
    "                                  threshold=THRESHOLD,\n",
    "                                  query_bundles=embedded_queries)\n",
    "evaluate_results(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, hotpot_qa_df = HotPotQA(SAMPLE=SAMPLE, DIFFICULTY=DIFFICULTY, SEED=SEED).get_data()\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df = pd.read_json(\"data/hotpot_test_fullwiki_v1.json\")#data\\hotpot_test_fullwiki_v1.json\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
