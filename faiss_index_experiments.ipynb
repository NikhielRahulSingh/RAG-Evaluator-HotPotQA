{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>actual_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard</td>\n",
       "      <td>George Boscawen, 9th Viscount Falmouth is a fo...</td>\n",
       "      <td>the Guards Division, Foot Guards regiments</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard</td>\n",
       "      <td>When Vladimir Kashpur portrayed Baba Yaga she ...</td>\n",
       "      <td>trio of sisters</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which musician has a solo punk rock project: T...</td>\n",
       "      <td>Frank Anthony Iero, Jr.</td>\n",
       "      <td>[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>A Disney voice actor has won which Emmy award?</td>\n",
       "      <td>Outstanding Supporting Actor</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>Which north-western suburb of Adelaide lies wi...</td>\n",
       "      <td>Birkenhead</td>\n",
       "      <td>[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level                                           question  \\\n",
       "0  hard  George Boscawen, 9th Viscount Falmouth is a fo...   \n",
       "1  hard  When Vladimir Kashpur portrayed Baba Yaga she ...   \n",
       "2  hard  Which musician has a solo punk rock project: T...   \n",
       "3  hard     A Disney voice actor has won which Emmy award?   \n",
       "4  hard  Which north-western suburb of Adelaide lies wi...   \n",
       "\n",
       "                                       answer  \\\n",
       "0  the Guards Division, Foot Guards regiments   \n",
       "1                             trio of sisters   \n",
       "2                     Frank Anthony Iero, Jr.   \n",
       "3                Outstanding Supporting Actor   \n",
       "4                                  Birkenhead   \n",
       "\n",
       "                            actual_contexts  \n",
       "0            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  \n",
       "2  [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]  \n",
       "3  [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]  \n",
       "4  [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = \"dunzhang/stella_en_400M_v5\"\n",
    "number = 5000\n",
    "difficulty = \"hard\"\n",
    "\n",
    "with open(f'embeddings/{model}/{difficulty}/{number}/df.pkl', 'rb') as file: hotpot_qa_df = pickle.load(file)\n",
    "with open(f'embeddings/{model}/{difficulty}/{number}/contexts.pkl', 'rb') as file: contexts = pickle.load(file)\n",
    "\n",
    "hotpot_qa_df['actual_contexts'] = hotpot_qa_df['actual_contexts'].apply(lambda x: [int(i) for i in x])\n",
    "\n",
    "query_embeddings = [query.embedding for query in hotpot_qa_df['question'].tolist()]\n",
    "query_strs = [query.query_str for query in hotpot_qa_df['question'].tolist()]\n",
    "\n",
    "context_texts = [textnode.text for textnode in contexts.values()]\n",
    "context_embeddings = [textnode.embedding for textnode in contexts.values()]\n",
    "\n",
    "benchmark_contexts = hotpot_qa_df['actual_contexts'].tolist()\n",
    "\n",
    "hotpot_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def lists_to_arrays(list_of_lists):\n",
    "    return np.array([np.array(lst) for lst in list_of_lists], dtype=object)\n",
    "\n",
    "def retrieve_contexts(index):\n",
    "    retrieved_results = [] \n",
    "    for query_embedding in tqdm(query_embeddings):\n",
    "        D, I = index.search(np.array(query_embedding).reshape(1, -1), 10)\n",
    "        results = I[0].tolist()\n",
    "        retrieved_results.append(results)\n",
    "    return retrieved_results\n",
    "\n",
    "def beir_evaluation(retrieved_contexts,benchmark_contexts = benchmark_contexts):\n",
    "    actual_contexts_dict = {\n",
    "        str(i): {str(doc_id): 1 for doc_id in context} for i, context in enumerate(retrieved_contexts)\n",
    "    }\n",
    "    results_dict = {\n",
    "        str(i): {str(doc_id): rank + 1 for rank, doc_id in enumerate(result)} for i, result in enumerate(benchmark_contexts)\n",
    "    }\n",
    "\n",
    "    ndcg, map_score, recall, precision = EvaluateRetrieval.evaluate(\n",
    "        actual_contexts_dict, results_dict, k_values=[10]\n",
    "    )\n",
    "\n",
    "    print(\"recall:\", recall)\n",
    "    print(\"precision:\", precision)\n",
    "    #print(\"acc:\", EvaluateRetrieval.evaluate_custom(actual_contexts_dict, results_dict, [10], metric=\"acc\"))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"ndcg:\", ndcg)\n",
    "    print(\"map:\", map_score)\n",
    "    print(\"mrr:\", EvaluateRetrieval.evaluate_custom(actual_contexts_dict, results_dict, [10], metric=\"mrr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Product (IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:48<00:00, 103.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.38146}\n",
      "precision: {'P@10': 0.38146}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.38303}\n",
      "map: {'MAP@10': 0.22887}\n",
      "mrr: {'MRR@10': 0.59057}\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatIP(len(query_embeddings[0]))\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "retrieved_contexts = retrieve_contexts(index)\n",
    "\n",
    "beir_evaluation(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:49<00:00, 101.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.38436}\n",
      "precision: {'P@10': 0.38436}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.38624}\n",
      "map: {'MAP@10': 0.23262}\n",
      "mrr: {'MRR@10': 0.59279}\n"
     ]
    }
   ],
   "source": [
    "index_l2 = faiss.IndexFlatL2(len(query_embeddings[0]))\n",
    "index_l2.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "retrieved_contexts = retrieve_contexts(index_l2)\n",
    "\n",
    "beir_evaluation(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Navigable Small World "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:08<00:00, 620.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.38414}\n",
      "precision: {'P@10': 0.38414}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.38595}\n",
      "map: {'MAP@10': 0.23256}\n",
      "mrr: {'MRR@10': 0.59194}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_neighbours = 10 # maximum number of neighbour connections a vector can have\n",
    "search_ef = 1000 # number of neighbours in the HNSW graph to explore when searching.\n",
    "search_ef = 500 # number of neighbours in the HNSW graph to explore when adding new vectors. \n",
    "\n",
    "index = faiss.IndexHNSWFlat(len(query_embeddings[0]), max_neighbours)\n",
    "index.hnsw.efSearch = search_ef\n",
    "index.hnsw.efConstruction = search_ef\n",
    "\n",
    "index.add(lists_to_arrays(context_embeddings))\n",
    "\n",
    "retrieved_contexts = retrieve_contexts(index)\n",
    "beir_evaluation(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 921.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.3712}\n",
      "precision: {'P@10': 0.3712}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.37269}\n",
      "map: {'MAP@10': 0.22263}\n",
      "mrr: {'MRR@10': 0.57608}\n"
     ]
    }
   ],
   "source": [
    "nlist = 5000  # how many voronoi cells\n",
    "nprobe = 50 # how many nearby voronoi cells to search\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(len(query_embeddings[0]))\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, len(query_embeddings[0]), nlist)\n",
    "index_ivf.train(lists_to_arrays(context_embeddings))\n",
    "index_ivf.add(lists_to_arrays(context_embeddings))\n",
    "index_ivf.nprobe = nprobe\n",
    "\n",
    "retrieved_contexts = retrieve_contexts(index_ivf)\n",
    "beir_evaluation(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical (BMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.49952}\n",
      "precision: {'P@10': 0.74928}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.75008}\n",
      "map: {'MAP@10': 0.42671}\n",
      "mrr: {'MRR@10': 0.85524}\n"
     ]
    }
   ],
   "source": [
    "from baguetter.indices import *\n",
    "\n",
    "index_lexical =  BM25SparseIndex(index_name=\"BMX_Test\")\n",
    "keys = {i: i + 1 for i in range(len(context_embeddings))}\n",
    "index_lexical.add_many(keys=keys,values=context_texts,show_progress=True)\n",
    "\n",
    "retrieved_contexts = []\n",
    "scores = []\n",
    "for question,embedding in zip(query_strs,query_embeddings):\n",
    "    x = index_lexical.search(query=question,top_k=15)\n",
    "    retrieved_contexts.append(x.keys)\n",
    "    scores.append(x.scores)\n",
    "\n",
    "beir_evaluation(retrieved_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:xformers:A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\nikhi\\anaconda3\\envs\\masters\\Lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "    ^^^^^^^^^^^^^\n",
      "ModuleNotFoundError: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"dunzhang/stella_en_400M_v5\"\n",
    "model_kwargs = {'device': 'cuda',\n",
    "                'trust_remote_code':True,}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=f\"D:/Users/nikhi/hugging_face_embedding_models/{model_name}\",\n",
    "    model_kwargs=model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "metadatas = [{\"id\":i} for i in range(len(context_texts))]\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    context_texts, metadatas=metadatas\n",
    ")\n",
    "bm25_retriever.k = 10\n",
    "\n",
    "kwargs = {\"embedding_function\":hf}\n",
    "text_embedding_pairs = zip(context_texts, context_embeddings)\n",
    "faiss_vector_store = FAISS.from_embeddings(text_embedding_pairs,context_embeddings)\n",
    "faiss_vector_store.embedding_function = hf\n",
    "faiss_retriever = faiss_vector_store.as_retriever(search_kwargs={\"k\": 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever,faiss_retriever], \n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 5000/5000 [36:15<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.48571}\n",
      "precision: {'P@10': 0.4435}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.46943}\n",
      "map: {'MAP@10': 0.31503}\n",
      "mrr: {'MRR@10': 0.63537}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def ensemble_retrieval(question):\n",
    "    x = ensemble_retriever.invoke(question)\n",
    "    retrieved_contexts = []\n",
    "\n",
    "    for _ in x:\n",
    "        retireved = []\n",
    "        try:\n",
    "            id = _.metadata[\"id\"]\n",
    "            retrieved_contexts.append(id)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return retrieved_contexts\n",
    "\n",
    "\n",
    "contexts = []\n",
    "for query in tqdm(query_strs, desc=\"Processing queries\"):\n",
    "    result = ensemble_retrieval(query)\n",
    "    contexts.append(result)\n",
    "\n",
    "beir_evaluation(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.48571}\n",
      "precision: {'P@10': 0.4435}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.46943}\n",
      "map: {'MAP@10': 0.31503}\n",
      "mrr: {'MRR@10': 0.63537}\n"
     ]
    }
   ],
   "source": [
    "#0.4 0. 6 \n",
    "\n",
    "recall: {'Recall@10': 0.48571}\n",
    "precision: {'P@10': 0.4435}\n",
    "\n",
    "ndcg: {'NDCG@10': 0.46943}\n",
    "map: {'MAP@10': 0.31503}\n",
    "mrr: {'MRR@10': 0.63537}\n",
    "\n",
    "#0.3, 0.7\n",
    "recall: {'Recall@10': 0.48571}\n",
    "precision: {'P@10': 0.4435}\n",
    "\n",
    "ndcg: {'NDCG@10': 0.46943}\n",
    "map: {'MAP@10': 0.31503}\n",
    "mrr: {'MRR@10': 0.63537}\n",
    "\n",
    "#05 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HybridSearch:\n",
    "    def __init__(self, lexical_index,contexts_dict=contexts):\n",
    "        self.lexical_index = lexical_index\n",
    "        self.contexts_dict = contexts_dict\n",
    "\n",
    "    def search(self, query, top_n):\n",
    "\n",
    "        lexical_retrived_docs = self.lexical_index.search(query=query.query_str,top_k=top_n*1)\n",
    "        lexical_retrieved_embeddings = [self.contexts_dict[str(i)].embedding for i in list(lexical_retrived_docs.keys)]\n",
    "    \n",
    "        semantic_index = faiss.IndexFlatIP(len(query.embedding))\n",
    "        semantic_index.add(lists_to_arrays(lexical_retrieved_embeddings))\n",
    "\n",
    "        D, I = semantic_index.search(np.array(query.embedding).reshape(1, -1), top_n)\n",
    "        semantic_retrieved_docs = I[0].tolist()\n",
    "        _ = [lexical_retrived_docs.keys[i] for i in semantic_retrieved_docs]\n",
    "\n",
    "        return _\n",
    "    \n",
    "def retrieve_contexts_parallel(hs):\n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "    retrieved_results = [None] * len(questions)\n",
    "    \n",
    "    def fetch_result(idx, query):\n",
    "        return idx, hs.search(query, top_n=10)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(fetch_result, idx, query) for idx, query in enumerate(questions)]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(questions)):\n",
    "            idx, result = future.result()\n",
    "            retrieved_results[idx] = result\n",
    "\n",
    "    return retrieved_results\n",
    "\n",
    "def retrieve_contexts(hs):\n",
    "    retrieved_results = [] \n",
    "    questions = hotpot_qa_df[\"question\"].tolist()\n",
    "    for query in tqdm(questions):\n",
    "        retrieved_results.append(hs.search(query, top_n=10))\n",
    "        \n",
    "    return retrieved_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 682.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: {'Recall@10': 0.64222}\n",
      "precision: {'P@10': 0.64222}\n",
      "\n",
      "ndcg: {'NDCG@10': 0.64413}\n",
      "map: {'MAP@10': 0.50007}\n",
      "mrr: {'MRR@10': 0.7928}\n"
     ]
    }
   ],
   "source": [
    "hs = HybridSearch(index_lexical)\n",
    "results = retrieve_contexts(hs)\n",
    "beir_evaluation(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall: {'Recall@10': 0.64222}\n",
    "precision: {'P@10': 0.64222}\n",
    "\n",
    "ndcg: {'NDCG@10': 0.64413}\n",
    "map: {'MAP@10': 0.50007}\n",
    "mrr: {'MRR@10': 0.7928}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
